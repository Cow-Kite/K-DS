{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78b216c-a7c8-4c6d-8161-96901469bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ModuleList\n",
    "import random\n",
    "import torch_geometric\n",
    "from sklearn.decomposition import PCA  # PCA 가져오기\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "learning_rate = 0.01\n",
    "d_o = 0.3\n",
    "epoch = 1000\n",
    "percent = 95\n",
    "\n",
    "# 시드 고정 함수\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch_geometric.seed_everything(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 시드 고정\n",
    "set_seed(42)\n",
    "\n",
    "# 데이터 로드\n",
    "file_path = 'new_df.csv'  # 실제 경로로 교체하세요\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "file_path = 'new_label.csv'  # 실제 경로로 교체하세요\n",
    "labels_df = pd.read_csv(file_path)\n",
    "\n",
    "# 라벨 텐서 생성\n",
    "y = torch.tensor(labels_df['label'].values, dtype=torch.long)\n",
    "\n",
    "# 트레인과 밸리데이션 데이터 나누기\n",
    "train_df = df.iloc[:17343]  \n",
    "val_df = df.iloc[17343:]  \n",
    "\n",
    "train_labels = y[:17343]\n",
    "val_labels = y[17343:]\n",
    "\n",
    "# 트레인 + 밸리데이션 데이터 합치기 (전체 데이터)\n",
    "all_df = pd.concat([train_df, val_df], axis=0)\n",
    "all_labels = torch.cat([train_labels, val_labels], dim=0)\n",
    "\n",
    "# 피어슨 상관계수로 엣지 리스트 생성 (전체 데이터에 대해)\n",
    "pearson_corr = all_df.corr(method='pearson')\n",
    "corr_array = pearson_corr.values\n",
    "np.fill_diagonal(corr_array, np.nan)\n",
    "flattened_corr = corr_array.flatten()\n",
    "valid_corr = flattened_corr[~np.isnan(flattened_corr)]\n",
    "top_percent_value = np.percentile(valid_corr, percent)\n",
    "edge_indices = np.argwhere(corr_array >= top_percent_value)\n",
    "edge_list = [[int(edge[0]), int(edge[1])] for edge in edge_indices]\n",
    "edge_tensor = torch.tensor(edge_list, dtype=torch.long).T\n",
    "\n",
    "# PyTorch 텐서로 변환\n",
    "all_tensor_data = torch.tensor(all_df.values, dtype=torch.float32)\n",
    "\n",
    "# PCA 적용하여 차원 축소\n",
    "pca = PCA(n_components=5) \n",
    "all_tensor_data = pca.fit_transform(all_tensor_data.numpy())\n",
    "all_tensor_data = torch.tensor(all_tensor_data, dtype=torch.float32)\n",
    "\n",
    "# 트레인/밸리데이션 마스크 생성\n",
    "train_mask = torch.zeros(all_df.shape[0], dtype=torch.bool)\n",
    "train_mask[:train_df.shape[0]] = True  # 첫 17343개의 노드는 트레인 데이터\n",
    "\n",
    "val_mask = torch.zeros(all_df.shape[0], dtype=torch.bool)\n",
    "val_mask[train_df.shape[0]:] = True  # 나머지는 발리데이션 데이터\n",
    "\n",
    "# 데이터 객체 생성 (전체 데이터)\n",
    "all_data = Data(x=all_tensor_data, edge_index=edge_tensor, y=all_labels, train_mask=train_mask, val_mask=val_mask)\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "all_data = all_data.to(device)\n",
    "num_classes = len(all_labels.unique())\n",
    "\n",
    "# GAT 모델 정의\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convs = ModuleList([\n",
    "            GATConv(all_data.num_node_features, 8, heads=8, dropout=d_o),\n",
    "            GATConv(8 * 8, num_classes, heads=1, concat=False, dropout=d_o),\n",
    "        ])\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != len(self.convs) - 1:\n",
    "                x = F.elu(x)\n",
    "                x = F.dropout(x, p=d_o, training=self.training)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# 학습 함수\n",
    "def train_node_classifier(model, graph, optimizer, criterion, n_epochs=epoch):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(graph)\n",
    "        loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])  # 트레인 마스크에 해당하는 노드만 학습\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "gcn = GAT().to(device)\n",
    "optimizer_gcn = torch.optim.Adam(gcn.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "gcn = train_node_classifier(gcn, all_data, optimizer_gcn, criterion)\n",
    "\n",
    "# Val 데이터에 대한 예측 및 정확도 계산 (전체 데이터로부터 마스크 사용)\n",
    "gcn.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred = gcn(all_data).argmax(dim=1)\n",
    "    correct_val = (val_pred[all_data.val_mask] == all_data.y[all_data.val_mask]).sum()\n",
    "    val_accuracy = int(correct_val) / all_data.val_mask.sum().item()\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Val 데이터셋에 대한 예측 정확도: {val_accuracy:.3f}')\n",
    "print(f'Val 데이터셋 실제 레이블: {all_data.y[all_data.val_mask]}')\n",
    "print(f'Val 데이터셋 예측된 레이블: {val_pred[all_data.val_mask]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
